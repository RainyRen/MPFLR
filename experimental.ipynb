{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "dataset = pd.read_csv('data.csv')\n",
    "\n",
    "# Extract the first 23 columns\n",
    "X_name = dataset.iloc[:, :23]  # Selecting all rows ':' and first 23 columns ':23'\n",
    "\n",
    "print(X_name)\n"
   ],
   "id": "35d5844aea3a5733",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y= dataset.iloc[:, 23]\n",
    "print(y)"
   ],
   "id": "1796979beb6850",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#指标1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# 读取数据\n",
    "dataset = pd.read_csv('data.csv')\n",
    "\n",
    "# 数据预处理 选择自变量x 因变量y\n",
    "X = dataset.iloc[:, :23].values\n",
    "y = dataset.iloc[:, 23].values\n",
    "\n",
    "# 划分数据集，训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# 数据标准化 特征标度\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 数据增强\n",
    "smote = ADASYN(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "# 开始训练随机森林模型\n",
    "classifier_rf = RandomForestClassifier(n_estimators=120, class_weight='balanced', criterion='entropy', random_state=42)\n",
    "classifier_rf.fit(X_train, y_train)\n",
    "\n",
    "# 随机森林预测\n",
    "y_pred_rf = classifier_rf.predict(X_test)\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "classifier_lr = LogisticRegression(random_state=42)\n",
    "classifier_lr.fit(X_train, y_train)\n",
    "\n",
    "# 逻辑回归预测\n",
    "y_pred_lr = classifier_lr.predict(X_test)\n",
    "\n",
    "#训练svc模型\n",
    "from sklearn.svm import SVC\n",
    "classifier_svc = SVC(random_state=42)\n",
    "classifier_svc.fit(X_train, y_train)\n",
    "# svc预测\n",
    "y_pred_svc = classifier_svc.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# 初始化决策树分类器\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 决策树预测\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# 训练MLP模型\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50,20 ), max_iter=500, alpha=0.0001, solver='adam', random_state=42)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测MLP模型\n",
    "y_pred_mlp = mlp_classifier.predict(X_test)\n",
    "\n",
    "# 训练KNN模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测KNN模型\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# 计算KNN模型的指标\n",
    "result_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"Confusion Matrix (KNN):\")\n",
    "print(result_knn)\n",
    "\n",
    "\n",
    "# 计算MLP模型的指标\n",
    "result_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "print(\"Confusion Matrix (MLP):\")\n",
    "print(result_mlp)\n",
    "\n",
    "# 随机森林指标\n",
    "result_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(result_rf)\n",
    "\"\"\"\n",
    "result1_rf = classification_report(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(result1_rf)\n",
    "result2_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", result2_rf)\n",
    "\"\"\"\n",
    "\n",
    "# 逻辑回归指标\n",
    "result_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(result_lr)\n",
    "\"\"\"\n",
    "result1_lr = classification_report(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(result1_lr)\n",
    "result2_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", result2_lr)\n",
    "\"\"\"\n",
    "\n",
    "# svc指标\n",
    "result_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"Support Vector Machine:\")\n",
    "print(result_svc)\n",
    "\n",
    "# 评估决策树模型\n",
    "result_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix (Decision Tree):\")\n",
    "print(result_dt)\n",
    "\n",
    "# ROC 曲线绘制\n",
    "fpr_rf, tpr_rf, threshold_rf = roc_curve(y_test, y_pred_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "fpr_lr, tpr_lr, threshold_lr = roc_curve(y_test, y_pred_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "fpr_svc, tpr_svc, threshold_svc = roc_curve(y_test, y_pred_svc)\n",
    "roc_auc_svc = auc(fpr_svc, tpr_svc)\n",
    "\n",
    "fpr_dt, tpr_dt, threshold_dt = roc_curve(y_test, y_pred_dt)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# 计算MLP模型的ROC曲线\n",
    "fpr_mlp, tpr_mlp, threshold_mlp = roc_curve(y_test, y_pred_mlp)\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "\n",
    "# 计算KNN模型的ROC曲线\n",
    "fpr_knn, tpr_knn, threshold_knn = roc_curve(y_test, y_pred_knn)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest AUC = {roc_auc_rf:.4f}')\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression AUC = {roc_auc_lr:.4f}')\n",
    "plt.plot(fpr_svc, tpr_svc, label=f'Support Vector Machine AUC = {roc_auc_svc:.4f}')\n",
    "plt.plot(fpr_dt, tpr_dt, label='Decision Tree AUC = %0.4f' % roc_auc_dt)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label='MLP AUC = %0.4f' % roc_auc_mlp)\n",
    "plt.plot(fpr_knn, tpr_knn, label='KNN AUC = %0.4f' % roc_auc_knn)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('1.jpg')\n",
    "plt.show()"
   ],
   "id": "8ffc9e82a59846be",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shap\n",
    "# 定义一个函数，返回 MLP 分类器的预测概率\n",
    "def predict_proba_func(X):\n",
    "    return mlp_classifier.predict_proba(X)[:, 1]  # 返回类别为 1 的概率\n",
    "\n",
    "# 创建 SHAP 解释器\n",
    "explainer = shap.KernelExplainer(predict_proba_func, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 绘制 Beeswarm plots\n",
    "shap.summary_plot(shap_values, X_test, feature_names=dataset.columns[:23],show=False)\n",
    "plt.savefig('1-shap.png')\n"
   ],
   "id": "a6354723a1a9202c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#指标2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# 读取数据\n",
    "dataset = pd.read_csv('data.csv')\n",
    "\n",
    "# 数据预处理 选择自变量x 因变量y\n",
    "X = dataset.iloc[:, :23].values\n",
    "y = dataset.iloc[:, 24].values\n",
    "\n",
    "# 划分数据集，训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# 数据标准化 特征标度\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 数据增强\n",
    "smote = ADASYN(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "# 开始训练随机森林模型\n",
    "classifier_rf = RandomForestClassifier(n_estimators=120, class_weight='balanced', criterion='entropy', random_state=42)\n",
    "classifier_rf.fit(X_train, y_train)\n",
    "\n",
    "# 随机森林预测\n",
    "y_pred_rf = classifier_rf.predict(X_test)\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "classifier_lr = LogisticRegression(random_state=42)\n",
    "classifier_lr.fit(X_train, y_train)\n",
    "\n",
    "# 逻辑回归预测\n",
    "y_pred_lr = classifier_lr.predict(X_test)\n",
    "\n",
    "#训练svc模型\n",
    "from sklearn.svm import SVC\n",
    "classifier_svc = SVC(random_state=42)\n",
    "classifier_svc.fit(X_train, y_train)\n",
    "# svc预测\n",
    "y_pred_svc = classifier_svc.predict(X_test)\n",
    "\n",
    "# 初始化决策树分类器\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 决策树预测\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# 训练MLP模型\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50,20 ), max_iter=500, alpha=0.0001, solver='adam', random_state=42)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测MLP模型\n",
    "y_pred_mlp = mlp_classifier.predict(X_test)\n",
    "\n",
    "# 训练KNN模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测KNN模型\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# 计算KNN模型的指标\n",
    "result_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"Confusion Matrix (KNN):\")\n",
    "print(result_knn)\n",
    "\n",
    "\n",
    "# 计算MLP模型的指标\n",
    "result_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "print(\"Confusion Matrix (MLP):\")\n",
    "print(result_mlp)\n",
    "\n",
    "# 随机森林指标\n",
    "result_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(result_rf)\n",
    "\"\"\"\n",
    "result1_rf = classification_report(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(result1_rf)\n",
    "result2_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", result2_rf)\n",
    "\"\"\"\n",
    "\n",
    "# 逻辑回归指标\n",
    "result_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(result_lr)\n",
    "\"\"\"\n",
    "result1_lr = classification_report(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(result1_lr)\n",
    "result2_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", result2_lr)\n",
    "\"\"\"\n",
    "\n",
    "# svc指标\n",
    "result_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"Support Vector Machine:\")\n",
    "print(result_svc)\n",
    "\n",
    "# 评估决策树模型\n",
    "result_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix (Decision Tree):\")\n",
    "print(result_dt)\n",
    "\n",
    "# ROC 曲线绘制\n",
    "fpr_rf, tpr_rf, threshold_rf = roc_curve(y_test, y_pred_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "fpr_lr, tpr_lr, threshold_lr = roc_curve(y_test, y_pred_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "fpr_svc, tpr_svc, threshold_svc = roc_curve(y_test, y_pred_svc)\n",
    "roc_auc_svc = auc(fpr_svc, tpr_svc)\n",
    "\n",
    "fpr_dt, tpr_dt, threshold_dt = roc_curve(y_test, y_pred_dt)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# 计算MLP模型的ROC曲线\n",
    "fpr_mlp, tpr_mlp, threshold_mlp = roc_curve(y_test, y_pred_mlp)\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "\n",
    "# 计算KNN模型的ROC曲线\n",
    "fpr_knn, tpr_knn, threshold_knn = roc_curve(y_test, y_pred_knn)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest AUC = {roc_auc_rf:.4f}')\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression AUC = {roc_auc_lr:.4f}')\n",
    "plt.plot(fpr_svc, tpr_svc, label=f'Support Vector Machine AUC = {roc_auc_svc:.4f}')\n",
    "plt.plot(fpr_dt, tpr_dt, label='Decision Tree AUC = %0.4f' % roc_auc_dt)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label='MLP AUC = %0.4f' % roc_auc_mlp)\n",
    "plt.plot(fpr_knn, tpr_knn, label='KNN AUC = %0.4f' % roc_auc_knn)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('2.jpg')\n",
    "plt.show()"
   ],
   "id": "e1921b78b443838",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shap\n",
    "# 定义一个函数，返回 MLP 分类器的预测概率\n",
    "def predict_proba_func(X):\n",
    "    return mlp_classifier.predict_proba(X)[:, 1]  # 返回类别为 1 的概率\n",
    "\n",
    "# 创建 SHAP 解释器\n",
    "explainer = shap.KernelExplainer(predict_proba_func, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 绘制 Beeswarm plots\n",
    "shap.summary_plot(shap_values, X_test, feature_names=dataset.columns[:23],show=False)\n",
    "plt.savefig('2-shap.png')"
   ],
   "id": "3441ebd3bdcab514",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#指标3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# 读取数据\n",
    "dataset = pd.read_csv('data.csv')\n",
    "\n",
    "# 数据预处理 选择自变量x 因变量y\n",
    "X = dataset.iloc[:, :23].values\n",
    "y = dataset.iloc[:, 25].values\n",
    "\n",
    "# 划分数据集，训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# 数据标准化 特征标度\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 数据增强\n",
    "smote = ADASYN(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "# 开始训练随机森林模型\n",
    "classifier_rf = RandomForestClassifier(n_estimators=120, class_weight='balanced', criterion='entropy', random_state=42)\n",
    "classifier_rf.fit(X_train, y_train)\n",
    "\n",
    "# 随机森林预测\n",
    "y_pred_rf = classifier_rf.predict(X_test)\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "classifier_lr = LogisticRegression(random_state=42)\n",
    "classifier_lr.fit(X_train, y_train)\n",
    "\n",
    "# 逻辑回归预测\n",
    "y_pred_lr = classifier_lr.predict(X_test)\n",
    "\n",
    "#训练svc模型\n",
    "from sklearn.svm import SVC\n",
    "classifier_svc = SVC(random_state=42)\n",
    "classifier_svc.fit(X_train, y_train)\n",
    "# svc预测\n",
    "y_pred_svc = classifier_svc.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# 初始化决策树分类器\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 决策树预测\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# 训练MLP模型\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50,20 ), max_iter=500, alpha=0.0001, solver='adam', random_state=42)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测MLP模型\n",
    "y_pred_mlp = mlp_classifier.predict(X_test)\n",
    "\n",
    "# 训练KNN模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测KNN模型\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# 计算KNN模型的指标\n",
    "result_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"Confusion Matrix (KNN):\")\n",
    "print(result_knn)\n",
    "\n",
    "\n",
    "# 计算MLP模型的指标\n",
    "result_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "print(\"Confusion Matrix (MLP):\")\n",
    "print(result_mlp)\n",
    "\n",
    "# 随机森林指标\n",
    "result_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(result_rf)\n",
    "\"\"\"\n",
    "result1_rf = classification_report(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(result1_rf)\n",
    "result2_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", result2_rf)\n",
    "\"\"\"\n",
    "\n",
    "# 逻辑回归指标\n",
    "result_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(result_lr)\n",
    "\"\"\"\n",
    "result1_lr = classification_report(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(result1_lr)\n",
    "result2_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", result2_lr)\n",
    "\"\"\"\n",
    "\n",
    "# svc指标\n",
    "result_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"Support Vector Machine:\")\n",
    "print(result_svc)\n",
    "\n",
    "# 评估决策树模型\n",
    "result_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix (Decision Tree):\")\n",
    "print(result_dt)\n",
    "\n",
    "# ROC 曲线绘制\n",
    "fpr_rf, tpr_rf, threshold_rf = roc_curve(y_test, y_pred_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "fpr_lr, tpr_lr, threshold_lr = roc_curve(y_test, y_pred_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "fpr_svc, tpr_svc, threshold_svc = roc_curve(y_test, y_pred_svc)\n",
    "roc_auc_svc = auc(fpr_svc, tpr_svc)\n",
    "\n",
    "fpr_dt, tpr_dt, threshold_dt = roc_curve(y_test, y_pred_dt)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# 计算MLP模型的ROC曲线\n",
    "fpr_mlp, tpr_mlp, threshold_mlp = roc_curve(y_test, y_pred_mlp)\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "\n",
    "# 计算KNN模型的ROC曲线\n",
    "fpr_knn, tpr_knn, threshold_knn = roc_curve(y_test, y_pred_knn)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest AUC = {roc_auc_rf:.4f}')\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression AUC = {roc_auc_lr:.4f}')\n",
    "plt.plot(fpr_svc, tpr_svc, label=f'Support Vector Machine AUC = {roc_auc_svc:.4f}')\n",
    "plt.plot(fpr_dt, tpr_dt, label='Decision Tree AUC = %0.4f' % roc_auc_dt)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label='MLP AUC = %0.4f' % roc_auc_mlp)\n",
    "plt.plot(fpr_knn, tpr_knn, label='KNN AUC = %0.4f' % roc_auc_knn)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('3.jpg')\n",
    "plt.show()"
   ],
   "id": "30bc665ca73aab4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shap\n",
    "\n",
    "# 定义一个函数，返回 SVC 分类器的决策函数\n",
    "def decision_function(X):\n",
    "    return classifier_svc.decision_function(X)  # 返回决策函数值\n",
    "\n",
    "# 创建 SHAP 解释器\n",
    "explainer_svc = shap.KernelExplainer(decision_function, X_train)\n",
    "shap_values_svc = explainer_svc.shap_values(X_test)\n",
    "\n",
    "# 绘制 Beeswarm plots\n",
    "shap.summary_plot(shap_values_svc, X_test, feature_names=dataset.columns[:23], show=False)\n",
    "plt.savefig('3-shap.png')\n"
   ],
   "id": "f47252db30260ccb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shap\n",
    "# 定义一个函数，返回 MLP 分类器的预测概率\n",
    "def predict_proba_func(X):\n",
    "    return mlp_classifier.predict_proba(X)[:, 1]  # 返回类别为 1 的概率\n",
    "\n",
    "# 创建 SHAP 解释器\n",
    "explainer = shap.KernelExplainer(predict_proba_func, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 绘制 Beeswarm plots\n",
    "shap.summary_plot(shap_values, X_test, feature_names=dataset.columns[:23],show=False)\n",
    "plt.savefig('3-shap.png')"
   ],
   "id": "4f2afbe2d48bac6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#指标4\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# 读取数据\n",
    "dataset = pd.read_csv('data.csv')\n",
    "\n",
    "# 数据预处理 选择自变量x 因变量y\n",
    "X = dataset.iloc[:, :23].values\n",
    "y = dataset.iloc[:, 26].values\n",
    "\n",
    "\n",
    "# 划分数据集，训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# 数据标准化 特征标度\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 数据增强\n",
    "smote = ADASYN(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "# 开始训练随机森林模型\n",
    "classifier_rf = RandomForestClassifier(n_estimators=120, class_weight='balanced', criterion='entropy', random_state=42)\n",
    "classifier_rf.fit(X_train, y_train)\n",
    "\n",
    "# 随机森林预测\n",
    "y_pred_rf = classifier_rf.predict(X_test)\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "classifier_lr = LogisticRegression(random_state=42)\n",
    "classifier_lr.fit(X_train, y_train)\n",
    "\n",
    "# 逻辑回归预测\n",
    "y_pred_lr = classifier_lr.predict(X_test)\n",
    "\n",
    "#训练svc模型\n",
    "from sklearn.svm import SVC\n",
    "classifier_svc = SVC(random_state=42)\n",
    "classifier_svc.fit(X_train, y_train)\n",
    "# svc预测\n",
    "y_pred_svc = classifier_svc.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# 初始化决策树分类器\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 决策树预测\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# 训练MLP模型\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50,20 ), max_iter=500, alpha=0.0001, solver='adam', random_state=42)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测MLP模型\n",
    "y_pred_mlp = mlp_classifier.predict(X_test)\n",
    "\n",
    "# 训练KNN模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测KNN模型\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# 计算KNN模型的指标\n",
    "result_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"Confusion Matrix (KNN):\")\n",
    "print(result_knn)\n",
    "\n",
    "\n",
    "# 计算MLP模型的指标\n",
    "result_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "print(\"Confusion Matrix (MLP):\")\n",
    "print(result_mlp)\n",
    "\n",
    "# 随机森林指标\n",
    "result_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(result_rf)\n",
    "\"\"\"\n",
    "result1_rf = classification_report(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(result1_rf)\n",
    "result2_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", result2_rf)\n",
    "\"\"\"\n",
    "\n",
    "# 逻辑回归指标\n",
    "result_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(result_lr)\n",
    "\"\"\"\n",
    "result1_lr = classification_report(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(result1_lr)\n",
    "result2_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", result2_lr)\n",
    "\"\"\"\n",
    "\n",
    "# svc指标\n",
    "result_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"Support Vector Machine:\")\n",
    "print(result_svc)\n",
    "\n",
    "# 评估决策树模型\n",
    "result_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix (Decision Tree):\")\n",
    "print(result_dt)\n",
    "\n",
    "# ROC 曲线绘制\n",
    "fpr_rf, tpr_rf, threshold_rf = roc_curve(y_test, y_pred_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "fpr_lr, tpr_lr, threshold_lr = roc_curve(y_test, y_pred_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "fpr_svc, tpr_svc, threshold_svc = roc_curve(y_test, y_pred_svc)\n",
    "roc_auc_svc = auc(fpr_svc, tpr_svc)\n",
    "\n",
    "fpr_dt, tpr_dt, threshold_dt = roc_curve(y_test, y_pred_dt)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# 计算MLP模型的ROC曲线\n",
    "fpr_mlp, tpr_mlp, threshold_mlp = roc_curve(y_test, y_pred_mlp)\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "\n",
    "# 计算KNN模型的ROC曲线\n",
    "fpr_knn, tpr_knn, threshold_knn = roc_curve(y_test, y_pred_knn)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest AUC = {roc_auc_rf:.4f}')\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression AUC = {roc_auc_lr:.4f}')\n",
    "plt.plot(fpr_svc, tpr_svc, label=f'Support Vector Machine AUC = {roc_auc_svc:.4f}')\n",
    "plt.plot(fpr_dt, tpr_dt, label='Decision Tree AUC = %0.4f' % roc_auc_dt)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label='MLP AUC = %0.4f' % roc_auc_mlp)\n",
    "plt.plot(fpr_knn, tpr_knn, label='KNN AUC = %0.4f' % roc_auc_knn)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('4.jpg')\n",
    "plt.show()"
   ],
   "id": "e0b467d72526411a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shap\n",
    "# 定义一个函数，返回 MLP 分类器的预测概率\n",
    "def predict_proba_func(X):\n",
    "    return mlp_classifier.predict_proba(X)[:, 1]  # 返回类别为 1 的概率\n",
    "\n",
    "# 创建 SHAP 解释器\n",
    "explainer = shap.KernelExplainer(predict_proba_func, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 绘制 Beeswarm plots\n",
    "shap.summary_plot(shap_values, X_test, feature_names=dataset.columns[:23],show=False)\n",
    "plt.savefig('4-shap.png')"
   ],
   "id": "c97e1be2d95ca0d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#指标5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# 读取数据\n",
    "dataset = pd.read_csv('data.csv')\n",
    "\n",
    "# 数据预处理 选择自变量x 因变量y\n",
    "X = dataset.iloc[:, :23].values\n",
    "y = dataset.iloc[:, 27].values\n",
    "\n",
    "# 划分数据集，训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# 数据标准化 特征标度\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 数据增强\n",
    "smote = ADASYN(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "# 开始训练随机森林模型\n",
    "classifier_rf = RandomForestClassifier(n_estimators=120, class_weight='balanced', criterion='entropy', random_state=42)\n",
    "classifier_rf.fit(X_train, y_train)\n",
    "\n",
    "# 随机森林预测\n",
    "y_pred_rf = classifier_rf.predict(X_test)\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "classifier_lr = LogisticRegression(random_state=42)\n",
    "classifier_lr.fit(X_train, y_train)\n",
    "\n",
    "# 逻辑回归预测\n",
    "y_pred_lr = classifier_lr.predict(X_test)\n",
    "\n",
    "#训练svc模型\n",
    "from sklearn.svm import SVC\n",
    "classifier_svc = SVC(random_state=42)\n",
    "classifier_svc.fit(X_train, y_train)\n",
    "# svc预测\n",
    "y_pred_svc = classifier_svc.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# 初始化决策树分类器\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 决策树预测\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# 训练MLP模型\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50,20 ), max_iter=500, alpha=0.0001, solver='adam', random_state=42)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测MLP模型\n",
    "y_pred_mlp = mlp_classifier.predict(X_test)\n",
    "\n",
    "# 训练KNN模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测KNN模型\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# 计算KNN模型的指标\n",
    "result_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"Confusion Matrix (KNN):\")\n",
    "print(result_knn)\n",
    "\n",
    "\n",
    "# 计算MLP模型的指标\n",
    "result_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "print(\"Confusion Matrix (MLP):\")\n",
    "print(result_mlp)\n",
    "\n",
    "# 随机森林指标\n",
    "result_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(result_rf)\n",
    "\"\"\"\n",
    "result1_rf = classification_report(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(result1_rf)\n",
    "result2_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", result2_rf)\n",
    "\"\"\"\n",
    "\n",
    "# 逻辑回归指标\n",
    "result_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(result_lr)\n",
    "\"\"\"\n",
    "result1_lr = classification_report(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(result1_lr)\n",
    "result2_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", result2_lr)\n",
    "\"\"\"\n",
    "\n",
    "# svc指标\n",
    "result_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"Support Vector Machine:\")\n",
    "print(result_svc)\n",
    "\n",
    "# 评估决策树模型\n",
    "result_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix (Decision Tree):\")\n",
    "print(result_dt)\n",
    "\n",
    "# ROC 曲线绘制\n",
    "fpr_rf, tpr_rf, threshold_rf = roc_curve(y_test, y_pred_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "fpr_lr, tpr_lr, threshold_lr = roc_curve(y_test, y_pred_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "fpr_svc, tpr_svc, threshold_svc = roc_curve(y_test, y_pred_svc)\n",
    "roc_auc_svc = auc(fpr_svc, tpr_svc)\n",
    "\n",
    "fpr_dt, tpr_dt, threshold_dt = roc_curve(y_test, y_pred_dt)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# 计算MLP模型的ROC曲线\n",
    "fpr_mlp, tpr_mlp, threshold_mlp = roc_curve(y_test, y_pred_mlp)\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "\n",
    "# 计算KNN模型的ROC曲线\n",
    "fpr_knn, tpr_knn, threshold_knn = roc_curve(y_test, y_pred_knn)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest AUC = {roc_auc_rf:.4f}')\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression AUC = {roc_auc_lr:.4f}')\n",
    "plt.plot(fpr_svc, tpr_svc, label=f'Support Vector Machine AUC = {roc_auc_svc:.4f}')\n",
    "plt.plot(fpr_dt, tpr_dt, label='Decision Tree AUC = %0.4f' % roc_auc_dt)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label='MLP AUC = %0.4f' % roc_auc_mlp)\n",
    "plt.plot(fpr_knn, tpr_knn, label='KNN AUC = %0.4f' % roc_auc_knn)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('5.jpg')\n",
    "plt.show()"
   ],
   "id": "f2dda82952991458",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shap\n",
    "\n",
    "# 定义一个函数，返回 SVC 分类器的决策函数\n",
    "def decision_function(X):\n",
    "    return classifier_svc.decision_function(X)  # 返回决策函数值\n",
    "\n",
    "# 创建 SHAP 解释器\n",
    "explainer_svc = shap.KernelExplainer(decision_function, X_train)\n",
    "shap_values_svc = explainer_svc.shap_values(X_test)\n",
    "\n",
    "# 绘制 Beeswarm plots\n",
    "shap.summary_plot(shap_values_svc, X_test, feature_names=dataset.columns[:23], show=False)\n",
    "plt.savefig('5-shap.png')\n"
   ],
   "id": "726b6ae25bf877cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import shap\n",
    "\n",
    "# 创建 SHAP 解释器（假设 classifier_rf 是随机森林模型）\n",
    "explainer = shap.TreeExplainer(classifier_rf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 绘制 Beeswarm plots\n",
    "shap.summary_plot(shap_values[1], X_test, feature_names=dataset.columns[:23], show=False)\n",
    "\n",
    "plt.savefig('5-shap.png')\n"
   ],
   "id": "979b6954724c4e48",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#指标6\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# 读取数据\n",
    "dataset = pd.read_csv('data.csv')\n",
    "\n",
    "# 数据预处理 选择自变量x 因变量y\n",
    "X = dataset.iloc[:, :23].values\n",
    "y = dataset.iloc[:, 28].values\n",
    "\n",
    "\n",
    "# 划分数据集，训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# 数据标准化 特征标度\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 数据增强\n",
    "smote = ADASYN(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "# 开始训练随机森林模型\n",
    "classifier_rf = RandomForestClassifier(n_estimators=120, class_weight='balanced', criterion='entropy', random_state=42)\n",
    "classifier_rf.fit(X_train, y_train)\n",
    "\n",
    "# 随机森林预测\n",
    "y_pred_rf = classifier_rf.predict(X_test)\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "classifier_lr = LogisticRegression(random_state=42)\n",
    "classifier_lr.fit(X_train, y_train)\n",
    "\n",
    "# 逻辑回归预测\n",
    "y_pred_lr = classifier_lr.predict(X_test)\n",
    "\n",
    "#训练svc模型\n",
    "from sklearn.svm import SVC\n",
    "classifier_svc = SVC(random_state=42)\n",
    "classifier_svc.fit(X_train, y_train)\n",
    "# svc预测\n",
    "y_pred_svc = classifier_svc.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# 初始化决策树分类器\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 决策树预测\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# 训练MLP模型\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50,20 ), max_iter=500, alpha=0.0001, solver='adam', random_state=42)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测MLP模型\n",
    "y_pred_mlp = mlp_classifier.predict(X_test)\n",
    "\n",
    "# 训练KNN模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测KNN模型\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# 计算KNN模型的指标\n",
    "result_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"Confusion Matrix (KNN):\")\n",
    "print(result_knn)\n",
    "\n",
    "\n",
    "# 计算MLP模型的指标\n",
    "result_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "print(\"Confusion Matrix (MLP):\")\n",
    "print(result_mlp)\n",
    "\n",
    "# 随机森林指标\n",
    "result_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(result_rf)\n",
    "\"\"\"\n",
    "result1_rf = classification_report(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(result1_rf)\n",
    "result2_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", result2_rf)\n",
    "\"\"\"\n",
    "\n",
    "# 逻辑回归指标\n",
    "result_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(result_lr)\n",
    "\"\"\"\n",
    "result1_lr = classification_report(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(result1_lr)\n",
    "result2_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", result2_lr)\n",
    "\"\"\"\n",
    "\n",
    "# svc指标\n",
    "result_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"Support Vector Machine:\")\n",
    "print(result_svc)\n",
    "\n",
    "# 评估决策树模型\n",
    "result_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix (Decision Tree):\")\n",
    "print(result_dt)\n",
    "\n",
    "# ROC 曲线绘制\n",
    "fpr_rf, tpr_rf, threshold_rf = roc_curve(y_test, y_pred_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "fpr_lr, tpr_lr, threshold_lr = roc_curve(y_test, y_pred_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "fpr_svc, tpr_svc, threshold_svc = roc_curve(y_test, y_pred_svc)\n",
    "roc_auc_svc = auc(fpr_svc, tpr_svc)\n",
    "\n",
    "fpr_dt, tpr_dt, threshold_dt = roc_curve(y_test, y_pred_dt)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# 计算MLP模型的ROC曲线\n",
    "fpr_mlp, tpr_mlp, threshold_mlp = roc_curve(y_test, y_pred_mlp)\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "\n",
    "# 计算KNN模型的ROC曲线\n",
    "fpr_knn, tpr_knn, threshold_knn = roc_curve(y_test, y_pred_knn)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest AUC = {roc_auc_rf:.4f}')\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression AUC = {roc_auc_lr:.4f}')\n",
    "plt.plot(fpr_svc, tpr_svc, label=f'Support Vector Machine AUC = {roc_auc_svc:.4f}')\n",
    "plt.plot(fpr_dt, tpr_dt, label='Decision Tree AUC = %0.4f' % roc_auc_dt)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label='MLP AUC = %0.4f' % roc_auc_mlp)\n",
    "plt.plot(fpr_knn, tpr_knn, label='KNN AUC = %0.4f' % roc_auc_knn)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('6.jpg')\n",
    "plt.show()"
   ],
   "id": "f994d51e9a44c492",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shap\n",
    "# 定义一个函数，返回 MLP 分类器的预测概率\n",
    "def predict_proba_func(X):\n",
    "    return mlp_classifier.predict_proba(X)[:, 1]  # 返回类别为 1 的概率\n",
    "\n",
    "# 创建 SHAP 解释器\n",
    "explainer = shap.KernelExplainer(predict_proba_func, X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 绘制 Beeswarm plots\n",
    "shap.summary_plot(shap_values, X_test, feature_names=dataset.columns[:23],show=False)\n",
    "plt.savefig('6-shap.png')"
   ],
   "id": "33b1b1d2d00ddfdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#指标7\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# 读取数据\n",
    "dataset = pd.read_csv('data.csv')\n",
    "\n",
    "# 数据预处理 选择自变量x 因变量y\n",
    "X = dataset.iloc[:, :23].values\n",
    "y = dataset.iloc[:, 29].values\n",
    "\n",
    "\n",
    "# 划分数据集，训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# 数据标准化 特征标度\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 数据增强\n",
    "smote = ADASYN(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "# 开始训练随机森林模型\n",
    "classifier_rf = RandomForestClassifier(n_estimators=120, class_weight='balanced', criterion='entropy', random_state=42)\n",
    "classifier_rf.fit(X_train, y_train)\n",
    "\n",
    "# 随机森林预测\n",
    "y_pred_rf = classifier_rf.predict(X_test)\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "classifier_lr = LogisticRegression(random_state=42)\n",
    "classifier_lr.fit(X_train, y_train)\n",
    "\n",
    "# 逻辑回归预测\n",
    "y_pred_lr = classifier_lr.predict(X_test)\n",
    "\n",
    "#训练svc模型\n",
    "from sklearn.svm import SVC\n",
    "classifier_svc = SVC(random_state=42)\n",
    "classifier_svc.fit(X_train, y_train)\n",
    "# svc预测\n",
    "y_pred_svc = classifier_svc.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# 初始化决策树分类器\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 决策树预测\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# 训练MLP模型\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50,20 ), max_iter=500, alpha=0.0001, solver='adam', random_state=42)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测MLP模型\n",
    "y_pred_mlp = mlp_classifier.predict(X_test)\n",
    "\n",
    "# 训练KNN模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 预测KNN模型\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# 计算KNN模型的指标\n",
    "result_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"Confusion Matrix (KNN):\")\n",
    "print(result_knn)\n",
    "\n",
    "\n",
    "# 计算MLP模型的指标\n",
    "result_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "print(\"Confusion Matrix (MLP):\")\n",
    "print(result_mlp)\n",
    "\n",
    "# 随机森林指标\n",
    "result_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(result_rf)\n",
    "\"\"\"\n",
    "result1_rf = classification_report(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(result1_rf)\n",
    "result2_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", result2_rf)\n",
    "\"\"\"\n",
    "\n",
    "# 逻辑回归指标\n",
    "result_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(result_lr)\n",
    "\"\"\"\n",
    "result1_lr = classification_report(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(result1_lr)\n",
    "result2_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", result2_lr)\n",
    "\"\"\"\n",
    "\n",
    "# svc指标\n",
    "result_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"Support Vector Machine:\")\n",
    "print(result_svc)\n",
    "\n",
    "# 评估决策树模型\n",
    "result_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix (Decision Tree):\")\n",
    "print(result_dt)\n",
    "\n",
    "# ROC 曲线绘制\n",
    "fpr_rf, tpr_rf, threshold_rf = roc_curve(y_test, y_pred_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "fpr_lr, tpr_lr, threshold_lr = roc_curve(y_test, y_pred_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "fpr_svc, tpr_svc, threshold_svc = roc_curve(y_test, y_pred_svc)\n",
    "roc_auc_svc = auc(fpr_svc, tpr_svc)\n",
    "\n",
    "fpr_dt, tpr_dt, threshold_dt = roc_curve(y_test, y_pred_dt)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# 计算MLP模型的ROC曲线\n",
    "fpr_mlp, tpr_mlp, threshold_mlp = roc_curve(y_test, y_pred_mlp)\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "\n",
    "# 计算KNN模型的ROC曲线\n",
    "fpr_knn, tpr_knn, threshold_knn = roc_curve(y_test, y_pred_knn)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest AUC = {roc_auc_rf:.4f}')\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression AUC = {roc_auc_lr:.4f}')\n",
    "plt.plot(fpr_svc, tpr_svc, label=f'Support Vector Machine AUC = {roc_auc_svc:.4f}')\n",
    "plt.plot(fpr_dt, tpr_dt, label='Decision Tree AUC = %0.4f' % roc_auc_dt)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label='MLP AUC = %0.4f' % roc_auc_mlp)\n",
    "plt.plot(fpr_knn, tpr_knn, label='KNN AUC = %0.4f' % roc_auc_knn)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('7.jpg')\n",
    "plt.show()"
   ],
   "id": "cd5f91ba2306a9ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shap\n",
    "\n",
    "# 定义一个函数，返回 SVC 分类器的决策函数\n",
    "def decision_function(X):\n",
    "    return classifier_svc.decision_function(X)  # 返回决策函数值\n",
    "\n",
    "# 创建 SHAP 解释器\n",
    "explainer_svc = shap.KernelExplainer(decision_function, X_train)\n",
    "shap_values_svc = explainer_svc.shap_values(X_test)\n",
    "\n",
    "# 绘制 Beeswarm plots\n",
    "shap.summary_plot(shap_values_svc, X_test, feature_names=dataset.columns[:23], show=False)\n",
    "plt.savefig('7-shap.png')\n"
   ],
   "id": "9a719908299261f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import shap\n",
    "\n",
    "# 创建 SHAP 解释器（假设 classifier_rf 是随机森林模型）\n",
    "explainer = shap.TreeExplainer(classifier_rf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 绘制 Beeswarm plots\n",
    "shap.summary_plot(shap_values[1], X_test, feature_names=dataset.columns[:23], show=False)\n",
    "\n",
    "plt.savefig('7-shap.png')"
   ],
   "id": "72b208d4b17e46",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
